{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from preprocessing import *\n",
    "from model import *\n",
    "import time\n",
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def find_latest_model(dir):\n",
    "    model_paths, epochs = [], []\n",
    "    for path in Path(dir).glob('*.pt'):\n",
    "        if 'epoch' not in path.stem:\n",
    "            continue\n",
    "        model_paths.append(path)\n",
    "        parts = path.stem.split('_')\n",
    "        epochs.append(int(parts[-1]))\n",
    "\n",
    "    if len(epochs) > 0:\n",
    "        epochs = np.array(epochs)\n",
    "        max_idx = np.argmax(epochs)\n",
    "        return model_paths[max_idx]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsMethod(object):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def PA(self):\n",
    "        pass\n",
    "    def CPA(self):\n",
    "        pass\n",
    "    def MPA(self):\n",
    "        pass\n",
    "    def Dice(self):\n",
    "        pass\n",
    "    def IOU(self):\n",
    "        pass\n",
    "    def MIOU(self):\n",
    "        pass\n",
    "    def mAP(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphVisualization(dataset: MyDataset, model=None, col=5, target_dir: str=\"./\"):\n",
    "    rows = ['Images', 'Ground\\nTruth\\nMasks', 'Ground\\nTruth\\nFusions',\n",
    "            'Prediction\\nMasks', 'Prediction\\nFusions', 'Prediction V.S.\\nGround Truth']\n",
    "    if model is None:\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=col, figsize=(10,10))\n",
    "\n",
    "        for i in range(3):\n",
    "            axes[i][0].annotate(rows[i], xy=(0, 0.5), xytext=(-30,60),\n",
    "                                xycoords='axes points', textcoords='offset points',\n",
    "                                size='large', ha='center', va='center')\n",
    "\n",
    "        for i in range(5):\n",
    "            filename = Path(dataset.imgPaths[i]).stem\n",
    "            data = dataset.__getitem__(i)\n",
    "            mask = np.array(data[1]).squeeze()\n",
    "            invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                                 std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                            transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                                 std = [ 1., 1., 1. ])])\n",
    "            img = invTrans(data[0])\n",
    "            img = np.array(img).transpose(1,2,0)\n",
    "\n",
    "            axes[0][i].set_title(filename, {'fontsize': 8})\n",
    "            axes[0][i].get_xaxis().set_visible(False)\n",
    "            axes[0][i].get_yaxis().set_visible(False)\n",
    "            axes[0][i].imshow(img)\n",
    "            axes[1][i].get_xaxis().set_visible(False)\n",
    "            axes[1][i].get_yaxis().set_visible(False)\n",
    "            axes[1][i].imshow(mask, cmap='magma')\n",
    "            axes[2][i].get_xaxis().set_visible(False)\n",
    "            axes[2][i].get_yaxis().set_visible(False)\n",
    "            axes[2][i].imshow(img)\n",
    "            axes[2][i].imshow(mask, cmap='twilight', alpha=0.6)\n",
    "\n",
    "        fig.tight_layout(h_pad=-25)\n",
    "        plt.savefig(os.path.join(target_dir, 'sample.png'), dpi=500)\n",
    "        plt.show()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    losses = Average()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input_var = Variable(input).to(device)\n",
    "            target_var = Variable(target).to(device)\n",
    "\n",
    "            output = model(input_var)\n",
    "            output = torch.argmax(output, dim=1, keepdim=True).float()\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            losses.update(loss.item(), input_var.size(0))\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, train_loader, model, criterion, optimizer, scheduler, validation):\n",
    "    wandb.watch(model, criterion=criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    latest_model_path = find_latest_model(model_dir)\n",
    "    best_model_path = os.path.join(*[model_dir, 'model_best.pt'])\n",
    "\n",
    "    if latest_model_path is not None:\n",
    "        state = torch.load(latest_model_path)\n",
    "        epoch = state['epoch']\n",
    "        model.load_state_dict(state['model'])\n",
    "        epoch = epoch\n",
    "\n",
    "        assert Path(best_model_path).exists() == True, f'best model path {best_model_path} does not exist'\n",
    "        best_state = torch.load(latest_model_path)\n",
    "        min_val_los = best_state['valid_loss']\n",
    "\n",
    "        print(f'Restored model at epoch {epoch}. Min validation loss : {min_val_los}')\n",
    "        epoch += 1\n",
    "        print(f'Started training model from epoch {epoch}')\n",
    "    else:\n",
    "        print('Started training model from epoch 0')\n",
    "        epoch = 0\n",
    "        min_val_los = 9999\n",
    "\n",
    "    valid_losses = []\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epoch, config['n_epoch'] + 1):\n",
    "\n",
    "        tq = tqdm(total=(len(train_loader) * config['batch_size']))\n",
    "        tq.set_description(f'Epoch {epoch}')\n",
    "\n",
    "        running_losses = Average()\n",
    "\n",
    "        model.train()\n",
    "        for i, (input_img, masks_true) in enumerate(train_loader):\n",
    "            input_img  = Variable(input_img, requires_grad=True).to(device)\n",
    "            masks_true = Variable(masks_true, requires_grad=True).to(device)\n",
    "\n",
    "            masks_pred = model(input_img)\n",
    "\n",
    "            masks_pred = torch.argmax(masks_pred, dim=1, keepdim=True).float()\n",
    "            masks_probs_flat = masks_pred.view(-1)\n",
    "            masks_true_flat  = masks_true.view(-1)\n",
    "\n",
    "            loss = criterion(masks_probs_flat, masks_true_flat)\n",
    "            running_losses.update(loss)\n",
    "\n",
    "            tq.set_postfix(loss='{:.5f}'.format(running_losses.avg))\n",
    "            tq.update(config['batch_size'])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        valid_loss = validation(model, valid_loader, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f'valid_loss = {valid_loss:.5f}')\n",
    "        tq.close()\n",
    "        \n",
    "        wandb.log({\"training_loss\": running_losses.avg})\n",
    "        wandb.log({\"valid_loss\": valid_loss})\n",
    "        \n",
    "        epoch_model_path = os.path.join(*[model_dir, f'model_epoch_{epoch}.pt'])\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'valid_loss': valid_loss,\n",
    "            'train_loss': running_losses.avg\n",
    "        }, epoch_model_path)\n",
    "\n",
    "        if valid_loss < min_val_los:\n",
    "            min_val_los = valid_loss\n",
    "            torch.save({\n",
    "                'model': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'valid_loss': valid_loss,\n",
    "                'train_loss': running_losses.avg\n",
    "            }, best_model_path)\n",
    "    \n",
    "    finished_training_time = (time.time()-start_time)\n",
    "    print(f\"training_time(s): \", finished_training_time)\n",
    "    wandb.log({\"training_time(s)\": finished_training_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    n_epoch         = 50,\n",
    "    batch_size      = 4,\n",
    "    lr              = 0.001,\n",
    "    num_workers     = 4,\n",
    "    momentum        = 0.9,\n",
    "    weight_decay    = 1e-4,\n",
    "    dataset         = \"CCAgT\",\n",
    "    model           = \"ResUNet\",\n",
    "    optimizer       = \"Adam\",\n",
    "    scheduler       = \"StepLR\"\n",
    ")\n",
    "\n",
    "wandb_init = dict(\n",
    "#     job_type: Optional[str] = None,\n",
    "#     dir = None,\n",
    "    config = config,\n",
    "    project = \"ResUNet with CCAgT dataset\",\n",
    "#     entity = None,\n",
    "#     reinit = None,\n",
    "    # tags = ['wgan_gp_1v1'],\n",
    "#     group = None,\n",
    "    name = None,\n",
    "    notes = None,\n",
    "#     magic = None,\n",
    "#     config_exclude_keys = None,\n",
    "#     config_include_keys = None,\n",
    "#     anonymous = None,\n",
    "    mode = \"online\",  # \"online\",\"offline\",\"disabled\"\n",
    "#     allow_val_change = None,\n",
    "#     resume = None,\n",
    "#     force = None,\n",
    "#     tensorboard = None,\n",
    "#     sync_tensorboard = None,\n",
    "#     monitor_gym = None,\n",
    "    save_code = True,\n",
    "#     settings=None\n",
    ")\n",
    "\n",
    "model_dir = \"./model\"\n",
    "orig_img_dir = \"./dataset/images\"\n",
    "orig_msk_dir = \"./dataset/masks\"\n",
    "save_json = \"./dataset/dataset.json\"\n",
    "save_samples = \"./dataset/samples\"\n",
    "\n",
    "if save_samples != '':\n",
    "    os.makedirs(save_samples, exist_ok=True)\n",
    "    for sample in Path(save_samples).glob('*.jpg'):\n",
    "        os.remove(str(sample))\n",
    "\n",
    "if not os.path.exists(save_json):\n",
    "    obtain_path(img_dir=orig_img_dir, mask_dir=orig_msk_dir, target_path=str(save_json))\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device 0 NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_id = 0\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.cuda.set_device(gpu_id)\n",
    "device = torch.device(\"cuda:{}\".format(str(gpu_id)) if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", torch.cuda.current_device(), torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = [0.485, 0.456, 0.406]\n",
    "channel_stds  = [0.229, 0.224, 0.225]\n",
    "\n",
    "dataset = divide_dataset(save_json, [0.7,0.1,0.2])\n",
    "\n",
    "train_tfms = transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Normalize(channel_means, channel_stds)])\n",
    "val_tfms = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(channel_means, channel_stds)])\n",
    "test_tfms = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(channel_means, channel_stds)])\n",
    "mask_tfms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_set = MyDataset(dataset, train_tfms, mask_tfms, 'train')\n",
    "valid_set = MyDataset(dataset, val_tfms, mask_tfms, 'valid')\n",
    "test_set = MyDataset(dataset, test_tfms, mask_tfms, 'test')\n",
    "\n",
    "train_loader = DataLoader(  train_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=torch.cuda.is_available(),\n",
    "                            num_workers=config['num_workers'])\n",
    "valid_loader = DataLoader(  valid_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=torch.cuda.is_available(),\n",
    "                            num_workers=config['num_workers'])\n",
    "test_loader = DataLoader(   test_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=torch.cuda.is_available(),\n",
    "                            num_workers=config['num_workers'])\n",
    "\n",
    "# GraphVisualization(test_set, model=None, col=5, target_dir=save_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mohmygoose0410\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "os.environ[\"WANDB_API_KEY\"] = \"a9932db05eeba1bfd135b895b1e586738f267083\"\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'main.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\master_course_materials\\Deep_Learning\\code\\2022-NYCU-AI-DL\\A5\\wandb\\run-20230112_234527-yzn59fop</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ohmygoose0410/ResUNet%20with%20CCAgT%20dataset/runs/yzn59fop\" target=\"_blank\">spring-blaze-3</a></strong> to <a href=\"https://wandb.ai/ohmygoose0410/ResUNet%20with%20CCAgT%20dataset\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model from epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:24<00:00,  1.22s/it, loss=4.44146]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss = 5.08239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: 100%|██████████| 20/20 [00:09<00:00,  2.11it/s, loss=4.43324]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss = 4.76066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_time(s):  37.74393177032471\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_loss</td><td>█▁</td></tr><tr><td>training_time(s)</td><td>▁</td></tr><tr><td>valid_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_loss</td><td>4.43324</td></tr><tr><td>training_time(s)</td><td>37.74393</td></tr><tr><td>valid_loss</td><td>4.76066</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">spring-blaze-3</strong>: <a href=\"https://wandb.ai/ohmygoose0410/ResUNet%20with%20CCAgT%20dataset/runs/yzn59fop\" target=\"_blank\">https://wandb.ai/ohmygoose0410/ResUNet%20with%20CCAgT%20dataset/runs/yzn59fop</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230112_234527-yzn59fop\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ResUNet(Block=ResBlock, DecBlock=DecBlock)\n",
    "optimizer = torch.optim.Adam(model.parameters(), config['lr'],\n",
    "                             weight_decay=config['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30, 0.1)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "run = wandb.init(**wandb_init)\n",
    "\n",
    "train(config, train_loader, model, criterion, optimizer, scheduler, validate)\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mas_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b78e932638e08554df05c20af87637e4b1aca929fdb8a300e51156ee9428db4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
