{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from preprocessing import *\n",
    "from model import *\n",
    "import time\n",
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def find_latest_model(dir):\n",
    "    model_paths, epochs = [], []\n",
    "    for path in Path(dir).glob('*.pt'):\n",
    "        if 'epoch' not in path.stem:\n",
    "            continue\n",
    "        model_paths.append(path)\n",
    "        parts = path.stem.split('_')\n",
    "        epochs.append(int(parts[-1]))\n",
    "\n",
    "    if len(epochs) > 0:\n",
    "        epochs = np.array(epochs)\n",
    "        max_idx = np.argmax(epochs)\n",
    "        return model_paths[max_idx]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsMethod(object):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def PA(self):\n",
    "        pass\n",
    "    def CPA(self):\n",
    "        pass\n",
    "    def MPA(self):\n",
    "        pass\n",
    "    def Dice(self):\n",
    "        pass\n",
    "    def IOU(self):\n",
    "        pass\n",
    "    def MIOU(self):\n",
    "        pass\n",
    "    def mAP(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(object):\n",
    "    def __init__(self, multiclass: bool = False, reduce_batch_first=True) -> None:\n",
    "        self.fn = self.multiclass_dice_coeff if multiclass else self.dice_coeff\n",
    "        self.reduce_batch_first = reduce_batch_first\n",
    "\n",
    "    def loss(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        return 1 - self.fn(input, target, reduce_batch_first=self.reduce_batch_first)\n",
    "\n",
    "    def dice_coeff(self, input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "        # Average of Dice coefficient for all batches, or for a single mask\n",
    "        assert input.size() == target.size()\n",
    "        assert input.dim() == 3 or not reduce_batch_first\n",
    "\n",
    "        sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n",
    "\n",
    "        inter = 2 * (input * target).sum(dim=sum_dim)\n",
    "        sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n",
    "        print(f\"{inter=}\")\n",
    "        print(f\"{sets_sum=}\")\n",
    "        sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
    "        print(f\"{sets_sum=}\\n\")\n",
    "\n",
    "        dice = (inter + epsilon) / (sets_sum + epsilon)\n",
    "        return dice.mean()\n",
    "\n",
    "    def multiclass_dice_coeff(self, input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "        # Average of Dice coefficient for all classes\n",
    "        return self.dice_coeff(input.flatten(0, 1), target.flatten(0, 1), reduce_batch_first, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphVisualization(dataset: MyDataset, model=None, col=5, target_dir: str=\"./\"):\n",
    "    rows = ['Images', 'Ground\\nTruth\\nMasks', 'Ground\\nTruth\\nFusions',\n",
    "            'Prediction\\nMasks', 'Prediction\\nFusions', 'Prediction V.S.\\nGround Truth']\n",
    "    if model is None:\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=col, figsize=(10,10))\n",
    "\n",
    "        for i in range(3):\n",
    "            axes[i][0].annotate(rows[i], xy=(0, 0.5), xytext=(-30,60),\n",
    "                                xycoords='axes points', textcoords='offset points',\n",
    "                                size='large', ha='center', va='center')\n",
    "\n",
    "        for i in range(5):\n",
    "            filename = Path(dataset.imgPaths[i]).stem\n",
    "            data = dataset.__getitem__(i)\n",
    "            mask = np.array(data[1]).squeeze()\n",
    "            invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                                 std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                            transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                                 std = [ 1., 1., 1. ])])\n",
    "            img = invTrans(data[0])\n",
    "            img = np.array(img).transpose(1,2,0)\n",
    "\n",
    "            axes[0][i].set_title(filename, {'fontsize': 8})\n",
    "            axes[0][i].get_xaxis().set_visible(False)\n",
    "            axes[0][i].get_yaxis().set_visible(False)\n",
    "            axes[0][i].imshow(img)\n",
    "            axes[1][i].get_xaxis().set_visible(False)\n",
    "            axes[1][i].get_yaxis().set_visible(False)\n",
    "            axes[1][i].imshow(mask, cmap='magma')\n",
    "            axes[2][i].get_xaxis().set_visible(False)\n",
    "            axes[2][i].get_yaxis().set_visible(False)\n",
    "            axes[2][i].imshow(img)\n",
    "            axes[2][i].imshow(mask, cmap='twilight', alpha=0.6)\n",
    "\n",
    "        fig.tight_layout(h_pad=-25)\n",
    "        plt.savefig(os.path.join(target_dir, 'sample.png'), dpi=500)\n",
    "        plt.show()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    losses = Average()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input_img  = Variable(input_img).to(device)\n",
    "            masks_true = Variable(masks_true).to(device)\n",
    "\n",
    "            masks_pred = model(input_img)\n",
    "            output = torch.argmax(masks_pred, dim=1)\n",
    "            # masks_pred = F.softmax(masks_pred, dim=1).float(),\n",
    "            # masks_true = F.one_hot(masks_true, 8).squeeze(1).permute(0, 3, 1, 2).float()\n",
    "            loss = criterion(output, masks_true)\n",
    "\n",
    "            losses.update(loss.item(), masks_true.size(0))\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, train_loader, model, criterion, optimizer, scheduler, validation):\n",
    "    wandb.watch(model, criterion=criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    latest_model_path = find_latest_model(model_dir)\n",
    "    best_model_path = os.path.join(*[model_dir, 'model_best.pt'])\n",
    "\n",
    "    if latest_model_path is not None:\n",
    "        state = torch.load(latest_model_path)\n",
    "        epoch = state['epoch']\n",
    "        model.load_state_dict(state['model'])\n",
    "        epoch = epoch\n",
    "\n",
    "        assert Path(best_model_path).exists() == True, f'best model path {best_model_path} does not exist'\n",
    "        best_state = torch.load(latest_model_path)\n",
    "        min_val_los = best_state['valid_loss']\n",
    "\n",
    "        print(f'Restored model at epoch {epoch}. Min validation loss : {min_val_los}')\n",
    "        epoch += 1\n",
    "        print(f'Started training model from epoch {epoch}')\n",
    "    else:\n",
    "        print('Started training model from epoch 0')\n",
    "        epoch = 0\n",
    "        min_val_los = 9999\n",
    "\n",
    "    valid_losses = []\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epoch, config['n_epoch'] + 1):\n",
    "\n",
    "        tq = tqdm(total=(len(train_loader) * config['batch_size']))\n",
    "        tq.set_description(f'Epoch {epoch}')\n",
    "\n",
    "        running_losses = Average()\n",
    "\n",
    "        model.train()\n",
    "        for i, (input_img, masks_true) in enumerate(train_loader):\n",
    "            input_img  = Variable(input_img, requires_grad=True).to(device, dtype=torch.float32)\n",
    "            masks_true = Variable(masks_true, requires_grad=True).to(device, dtype=torch.long)\n",
    "\n",
    "            masks_pred = model(input_img)\n",
    "            # masks_pred = F.softmax(masks_pred, dim=1).float()\n",
    "            # masks_true = F.one_hot(masks_true.squeeze(1), 8).permute(0, 3, 1, 2).float()\n",
    "            masks_true = F.one_hot(masks_true.squeeze(1), 8).permute(0, 3, 1, 2).float()\n",
    "            print(\"pred shape: \", masks_pred.size())\n",
    "            print(\"true shape: \", masks_true.size())\n",
    "            loss = criterion(masks_pred, masks_true)\n",
    "            running_losses.update(loss)\n",
    "\n",
    "            tq.set_postfix(loss='{:.5f}'.format(running_losses.avg))\n",
    "            tq.update(config['batch_size'])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        valid_loss = validation(model, valid_loader, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f'valid_loss = {valid_loss:.5f}')\n",
    "        tq.close()\n",
    "        \n",
    "        wandb.log({\"training_loss\": running_losses.avg})\n",
    "        wandb.log({\"valid_loss\": valid_loss})\n",
    "        \n",
    "        epoch_model_path = os.path.join(*[model_dir, f'model_epoch_{epoch}.pt'])\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'valid_loss': valid_loss,\n",
    "            'train_loss': running_losses.avg\n",
    "        }, epoch_model_path)\n",
    "\n",
    "        if valid_loss < min_val_los:\n",
    "            min_val_los = valid_loss\n",
    "            torch.save({\n",
    "                'model': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'valid_loss': valid_loss,\n",
    "                'train_loss': running_losses.avg\n",
    "            }, best_model_path)\n",
    "    \n",
    "    finished_training_time = (time.time()-start_time)\n",
    "    print(f\"training_time(s): \", finished_training_time)\n",
    "    wandb.log({\"training_time(s)\": finished_training_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    n_epoch         = 50,\n",
    "    batch_size      = 1,\n",
    "    lr              = 0.001,\n",
    "    num_workers     = 0,\n",
    "    momentum        = 0.9,\n",
    "    weight_decay    = 1e-4,\n",
    "    dataset         = \"CCAgT\",\n",
    "    model           = \"ResUNet\",\n",
    "    optimizer       = \"Adam\",\n",
    "    scheduler       = \"StepLR\"\n",
    ")\n",
    "\n",
    "wandb_init = dict(\n",
    "#     job_type: Optional[str] = None,\n",
    "#     dir = None,\n",
    "    config = config,\n",
    "    project = \"ResUNet with CCAgT dataset\",\n",
    "#     entity = None,\n",
    "#     reinit = None,\n",
    "    # tags = ['wgan_gp_1v1'],\n",
    "#     group = None,\n",
    "    name = None,\n",
    "    notes = None,\n",
    "#     magic = None,\n",
    "#     config_exclude_keys = None,\n",
    "#     config_include_keys = None,\n",
    "#     anonymous = None,\n",
    "    mode = \"online\",  # \"online\",\"offline\",\"disabled\"\n",
    "#     allow_val_change = None,\n",
    "#     resume = None,\n",
    "#     force = None,\n",
    "#     tensorboard = None,\n",
    "#     sync_tensorboard = None,\n",
    "#     monitor_gym = None,\n",
    "    save_code = True,\n",
    "#     settings=None\n",
    ")\n",
    "\n",
    "model_dir = \"./model\"\n",
    "orig_img_dir = \"./dataset/images\"\n",
    "orig_msk_dir = \"./dataset/masks\"\n",
    "save_json = \"./dataset/dataset.json\"\n",
    "save_samples = \"./dataset/samples\"\n",
    "\n",
    "if save_samples != '':\n",
    "    os.makedirs(save_samples, exist_ok=True)\n",
    "    for sample in Path(save_samples).glob('*.jpg'):\n",
    "        os.remove(str(sample))\n",
    "\n",
    "if not os.path.exists(save_json):\n",
    "    obtain_path(img_dir=orig_img_dir, mask_dir=orig_msk_dir, target_path=str(save_json))\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.cuda.set_device(gpu_id)\n",
    "# device = torch.device(\"cuda:{}\".format(str(gpu_id)) if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "# print(\"device\", torch.cuda.current_device(), torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = [0.485, 0.456, 0.406]\n",
    "channel_stds  = [0.229, 0.224, 0.225]\n",
    "\n",
    "dataset = divide_dataset(save_json, [0.7,0.1,0.2])\n",
    "\n",
    "train_tsfm = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize(channel_means, channel_stds),\n",
    "                                transforms.RandomCrop((832, 832)), \n",
    "                                transforms.RandomRotation(90), \n",
    "                                transforms.RandomHorizontalFlip()])\n",
    "val_tsfm = transforms.Compose([ transforms.ToTensor(), \n",
    "                                transforms.Normalize(channel_means, channel_stds),\n",
    "                                transforms.RandomCrop((832, 832))])\n",
    "test_tsfm = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize(channel_means, channel_stds),\n",
    "                                transforms.RandomCrop((832, 832))])\n",
    "train_mask_tsfm = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.RandomCrop((832, 832)),\n",
    "                                      transforms.RandomRotation(90),\n",
    "                                      transforms.RandomHorizontalFlip()])\n",
    "mask_tsfm = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.RandomCrop((832, 832)), \n",
    "                                transforms.RandomRotation(90)])\n",
    "\n",
    "train_set = MyDataset(dataset, train_tsfm, train_mask_tsfm, 'train')\n",
    "valid_set = MyDataset(dataset, val_tsfm, mask_tsfm, 'valid')\n",
    "test_set = MyDataset(dataset, test_tsfm, mask_tsfm, 'test')\n",
    "\n",
    "train_loader = DataLoader(  train_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=torch.cuda.is_available(),\n",
    "                            num_workers=config['num_workers'])\n",
    "valid_loader = DataLoader(  valid_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=torch.cuda.is_available(),\n",
    "                            num_workers=config['num_workers'])\n",
    "test_loader = DataLoader(   test_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=torch.cuda.is_available(),\n",
    "                            num_workers=config['num_workers'])\n",
    "\n",
    "# GraphVisualization(test_set, model=None, col=5, target_dir=save_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mohmygoose0410\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "os.environ[\"WANDB_API_KEY\"] = \"a9932db05eeba1bfd135b895b1e586738f267083\"\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'main.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\master_course_materials\\Deep_Learning\\code\\2022-NYCU-AI-DL\\A5\\wandb\\run-20230115_125244-3pzo7inm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ohmygoose0410/ResUNet%20with%20CCAgT%20dataset/runs/3pzo7inm\" target=\"_blank\">usual-blaze-50</a></strong> to <a href=\"https://wandb.ai/ohmygoose0410/ResUNet%20with%20CCAgT%20dataset\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model from epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/6537 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred shape:  torch.Size([1, 8, 832, 832])\n",
      "true shape:  torch.Size([1, 1, 832, 832])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([1, 1, 832, 832])) must be the same as input size (torch.Size([1, 8, 832, 832]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m run \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39minit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mwandb_init)\n\u001b[1;32m---> 11\u001b[0m train(config, train_loader, model, criterion, optimizer, scheduler, validate)\n\u001b[0;32m     13\u001b[0m run\u001b[39m.\u001b[39mfinish()\n",
      "Cell \u001b[1;32mIn [7], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config, train_loader, model, criterion, optimizer, scheduler, validation)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpred shape: \u001b[39m\u001b[39m\"\u001b[39m, masks_pred\u001b[39m.\u001b[39msize())\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrue shape: \u001b[39m\u001b[39m\"\u001b[39m, masks_true\u001b[39m.\u001b[39msize())\n\u001b[1;32m---> 45\u001b[0m loss \u001b[39m=\u001b[39m criterion(masks_pred, masks_true)\n\u001b[0;32m     46\u001b[0m running_losses\u001b[39m.\u001b[39mupdate(loss)\n\u001b[0;32m     48\u001b[0m tq\u001b[39m.\u001b[39mset_postfix(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{:.5f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(running_losses\u001b[39m.\u001b[39mavg))\n",
      "File \u001b[1;32mc:\\Users\\peter\\miniconda3\\envs\\mas_deep_learning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\peter\\miniconda3\\envs\\mas_deep_learning\\lib\\site-packages\\torch\\nn\\modules\\loss.py:714\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 714\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39;49m, target,\n\u001b[0;32m    715\u001b[0m                                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    716\u001b[0m                                               pos_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_weight,\n\u001b[0;32m    717\u001b[0m                                               reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\peter\\miniconda3\\envs\\mas_deep_learning\\lib\\site-packages\\torch\\nn\\functional.py:3148\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3145\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()):\n\u001b[1;32m-> 3148\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTarget size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) must be the same as input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()))\n\u001b[0;32m   3150\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([1, 1, 832, 832])) must be the same as input size (torch.Size([1, 8, 832, 832]))"
     ]
    }
   ],
   "source": [
    "model = ResUNet(Block=ResBlock, DecBlock=DecBlock)\n",
    "optimizer = torch.optim.Adam(model.parameters(), config['lr'],\n",
    "                             weight_decay=config['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30, 0.1)\n",
    "criterion = BCEWithLogitsLoss().to(device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "run = wandb.init(**wandb_init)\n",
    "\n",
    "train(config, train_loader, model, criterion, optimizer, scheduler, validate)\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mas_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b78e932638e08554df05c20af87637e4b1aca929fdb8a300e51156ee9428db4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
