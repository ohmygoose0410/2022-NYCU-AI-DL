{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from preprocessing import *\n",
    "from model import *\n",
    "import time\n",
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def find_latest_model(dir):\n",
    "    model_paths, epochs = [], []\n",
    "    for path in Path(dir).glob('*.pt'):\n",
    "        if 'epoch' not in path.stem:\n",
    "            continue\n",
    "        model_paths.append(path)\n",
    "        parts = path.stem.split('_')\n",
    "        epochs.append(int(parts[-1]))\n",
    "\n",
    "    if len(epochs) > 0:\n",
    "        epochs = np.array(epochs)\n",
    "        max_idx = np.argmax(epochs)\n",
    "        return model_paths[max_idx]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsMethod(object):\n",
    "    def __init__(self, prob_pred_masks: Tensor, true_masks: Tensor, num_class: int, smooth: float=1e-7) -> None:\n",
    "        self.prob_pred_masks = prob_pred_masks\n",
    "        self.true_masks = true_masks\n",
    "        y_pred = torch.argmax(prob_pred_masks, dim=1)\n",
    "        y_true = true_masks\n",
    "        assert y_pred.size() == y_true.size(), \"Input size and target size is not matching\"\n",
    "\n",
    "        self.matrix = self.confusion_matrix(y_pred, y_true)\n",
    "        self.num_class = num_class\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def PA(self):\n",
    "        return torch.diagonal(self.matrix,0).sum() / self.matrix.sum()\n",
    "\n",
    "    def CPA(self):\n",
    "        cpa_list = list()\n",
    "        for idx in range(self.num_class):\n",
    "            cpa_list.append((self.matrix[idx,idx] + self.smooth)/ \\\n",
    "                            (self.matrix[:,idx].sum() + self.smooth))\n",
    "        return np.array(cpa_list)\n",
    "\n",
    "    def MPA(self):\n",
    "        return self.CPA().sum() / self.num_class\n",
    "\n",
    "    def Dice(self):\n",
    "        pass\n",
    "\n",
    "    def IoU(self):\n",
    "        iou_list = list()\n",
    "        for idx in range(self.num_class):\n",
    "            iou_list.append((self.matrix[idx,idx] + self.smooth)/ \\\n",
    "                            (self.matrix[:,idx].sum() + self.matrix[idx,:].sum() \\\n",
    "                            - self.matrix[idx,idx] + self.smooth))\n",
    "        return np.array(iou_list)\n",
    "\n",
    "    def MIoU(self):\n",
    "        return self.IoU().sum() / self.num_class\n",
    "\n",
    "    def BinIoU(self, pred_masks, true_masks):\n",
    "        pred_masks, true_masks = pred_masks.flatten(), true_masks.flatten()\n",
    "        inter = (pred_masks * true_masks).sum()\n",
    "        union = ((pred_masks + true_masks) > 0).sum()\n",
    "        return inter / union\n",
    "\n",
    "    def mAP(self, thres: list=[0.5]):\n",
    "        input = self.prob_pred_masks\n",
    "        input = input.numpy()\n",
    "        one_hot_true_masks = F.one_hot(self.true_masks.squeeze(1), 8).permute(0, 3, 1, 2).numpy()\n",
    "        sum_PA = 0\n",
    "        mPA = 0\n",
    "        for d in range(input.shape[1]):\n",
    "            t_input = np.zeros(input.shape)\n",
    "            for t in thres:\n",
    "                t_input[input >= t] = 1\n",
    "                sum_PA += self.BinIoU(t_input[:,d,:,:], one_hot_true_masks[:,d,:,:])\n",
    "            mPA += (sum_PA / len(thres))\n",
    "        return mPA / self.num_class\n",
    "        \n",
    "    def confusion_matrix(self, y_pred, y_true):\n",
    "        N = max(max(y_true), max(y_pred)) + 1\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long)\n",
    "        return torch.sparse.LongTensor(\n",
    "            torch.stack([y_true, y_pred]), \n",
    "            torch.ones_like(y_true, dtype=torch.long),\n",
    "            torch.Size([N, N])).to_dense().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(object):\n",
    "    def __init__(self, multiclass: bool = False, reduce_batch_first=True) -> None:\n",
    "        self.fn = self.multiclass_dice_coeff if multiclass else self.dice_coeff\n",
    "        self.reduce_batch_first = reduce_batch_first\n",
    "\n",
    "    def loss(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        return 1 - self.fn(input, target, reduce_batch_first=self.reduce_batch_first)\n",
    "\n",
    "    def dice_coeff(self, input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "        # Average of Dice coefficient for all batches, or for a single mask\n",
    "        assert input.size() == target.size()\n",
    "        assert input.dim() == 3 or not reduce_batch_first\n",
    "\n",
    "        sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n",
    "\n",
    "        inter = 2 * (input * target).sum(dim=sum_dim)\n",
    "        sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n",
    "        print(f\"{inter=}\")\n",
    "        print(f\"{sets_sum=}\")\n",
    "        sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
    "        print(f\"{sets_sum=}\\n\")\n",
    "\n",
    "        dice = (inter + epsilon) / (sets_sum + epsilon)\n",
    "        return dice.mean()\n",
    "\n",
    "    def multiclass_dice_coeff(self, input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "        # Average of Dice coefficient for all classes\n",
    "        return self.dice_coeff(input.flatten(0, 1), target.flatten(0, 1), reduce_batch_first, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(model_dir: str, target_dir: str, title: str):\n",
    "    paths = [path for path in Path(model_dir).glob('*.pt')]\n",
    "    paths = sorted(paths)\n",
    "    epochs = []\n",
    "    tr_losses = []\n",
    "    vl_losses = []\n",
    "    for path in tqdm(paths):\n",
    "        if 'epoch' not in path.stem:\n",
    "            continue\n",
    "        parts = path.stem.split('_')\n",
    "        epoch = int(parts[-1])\n",
    "        epochs.append(epoch)\n",
    "        state = torch.load(path)\n",
    "        val_los = state['valid_loss']\n",
    "        train_loss = float(state['train_loss'])\n",
    "        tr_losses.append(train_loss)\n",
    "        vl_losses.append(val_los)\n",
    "\n",
    "    sorted_idxs = np.argsort(epochs)\n",
    "    tr_losses = [tr_losses[idx] for idx in sorted_idxs]\n",
    "    vl_losses = [vl_losses[idx] for idx in sorted_idxs]\n",
    "\n",
    "    data = {}\n",
    "    data['tr_losses']=tr_losses\n",
    "    data['vl_losses']=vl_losses\n",
    "    with open(os.path.join(target_dir, 'training_loss.json'), 'w', newline='') as jsonfile:\n",
    "        json.dump(data, jsonfile)\n",
    "\n",
    "    plt.plot(tr_losses[1:], label='train_loss')\n",
    "    plt.plot(vl_losses[1:], label='valid_loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(target_dir, 'training_loss.jpg'), dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphVisualization(dataset: MyDataset, model=None, col=5, target_dir: str=\"./\"):\n",
    "    rows = ['Images', 'Ground\\nTruth\\nMasks', 'Ground\\nTruth\\nFusions',\n",
    "            'Prediction\\nMasks', 'Prediction\\nFusions', 'Prediction V.S.\\nGround Truth']\n",
    "    if model is None:\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=col, figsize=(10,10))\n",
    "        fig.patch.set_facecolor('white')\n",
    "\n",
    "        for i in range(3):\n",
    "            axes[i][0].annotate(rows[i], xy=(0, 0.5), xytext=(-30,60),\n",
    "                                xycoords='axes points', textcoords='offset points',\n",
    "                                size='large', ha='center', va='center')\n",
    "\n",
    "        for i in range(col):\n",
    "            filename = Path(dataset.imgPaths[i]).stem\n",
    "            data = dataset.__getitem__(i)\n",
    "            mask = np.array(data[1]).squeeze()\n",
    "            invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                                 std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                            transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                                 std = [ 1., 1., 1. ])])\n",
    "            img = invTrans(data[0])\n",
    "            img = np.array(img).transpose(1,2,0)\n",
    "\n",
    "            axes[0][i].set_title(filename, {'fontsize': 8})\n",
    "            axes[0][i].get_xaxis().set_visible(False)\n",
    "            axes[0][i].get_yaxis().set_visible(False)\n",
    "            axes[0][i].imshow(img)\n",
    "            axes[1][i].get_xaxis().set_visible(False)\n",
    "            axes[1][i].get_yaxis().set_visible(False)\n",
    "            axes[1][i].imshow(mask, cmap='magma')\n",
    "            axes[2][i].get_xaxis().set_visible(False)\n",
    "            axes[2][i].get_yaxis().set_visible(False)\n",
    "            axes[2][i].imshow(img)\n",
    "            axes[2][i].imshow(mask, cmap='twilight', alpha=0.6)\n",
    "\n",
    "        fig.tight_layout(h_pad=-25)\n",
    "        plt.savefig(os.path.join(target_dir, 'sample.png'), dpi=500)\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, axes = plt.subplots(nrows=5, ncols=col, figsize=(10,10))\n",
    "        fig.patch.set_facecolor('white')\n",
    "\n",
    "        for i in range(5):\n",
    "            axes[i][0].annotate(rows[i], xy=(0, 0.5), xytext=(-45,45),\n",
    "                                xycoords='axes points', textcoords='offset points',\n",
    "                                size='large', ha='center', va='center')\n",
    "\n",
    "        for i in range(col):\n",
    "            filename = Path(dataset.imgPaths[i]).stem\n",
    "            data = dataset.__getitem__(i)\n",
    "            mask = np.array(data[1]).squeeze()\n",
    "            invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                                 std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                            transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                                 std = [ 1., 1., 1. ])])\n",
    "            img = invTrans(data[0])\n",
    "            img = np.array(img).transpose(1,2,0)\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                input_img  = Variable(torch.unsqueeze(data[0], 0)).to(device, dtype=torch.float32)\n",
    "                masks_true = Variable(torch.unsqueeze(data[1], 0)).to(device, dtype=torch.long)\n",
    "                masks_pred = model(input_img)\n",
    "                pred_mask = torch.argmax(masks_pred, dim=1).squeeze(0).cpu()\n",
    "\n",
    "            axes[0][i].set_title(filename, {'fontsize': 8})\n",
    "            axes[0][i].get_xaxis().set_visible(False)\n",
    "            axes[0][i].get_yaxis().set_visible(False)\n",
    "            axes[0][i].imshow(img)\n",
    "            axes[1][i].get_xaxis().set_visible(False)\n",
    "            axes[1][i].get_yaxis().set_visible(False)\n",
    "            axes[1][i].imshow(mask, cmap='magma')\n",
    "            axes[2][i].get_xaxis().set_visible(False)\n",
    "            axes[2][i].get_yaxis().set_visible(False)\n",
    "            axes[2][i].imshow(img)\n",
    "            axes[2][i].imshow(mask, cmap='twilight', alpha=0.6)\n",
    "\n",
    "            axes[3][i].get_xaxis().set_visible(False)\n",
    "            axes[3][i].get_yaxis().set_visible(False)\n",
    "            axes[3][i].imshow(pred_mask, cmap='magma')\n",
    "            axes[4][i].get_xaxis().set_visible(False)\n",
    "            axes[4][i].get_yaxis().set_visible(False)\n",
    "            axes[4][i].imshow(img)\n",
    "            axes[4][i].imshow(pred_mask, cmap='twilight', alpha=0.6)\n",
    "#             axes[5][i].get_xaxis().set_visible(False)\n",
    "#             axes[5][i].get_yaxis().set_visible(False)\n",
    "#             axes[5][i].imshow(pred_mask, cmap='magma')\n",
    "#             axes[2][i].imshow(mask, cmap='twilight', alpha=0.6)\n",
    "\n",
    "        fig.tight_layout(h_pad=1)\n",
    "        plt.savefig(os.path.join(target_dir, 'sample_pred.png'), dpi=500)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, model_dir):\n",
    "    method = {'pa': list(),\n",
    "             'cpa': list(),\n",
    "             'mpa': list(),\n",
    "             'iou': list(),\n",
    "             'miou': list(),\n",
    "             'map': list()}\n",
    "\n",
    "    best_model_path = os.path.join(*[model_dir, 'model_best.pt'])\n",
    "    state = torch.load(best_model_path)\n",
    "    model.load_state_dict(state['model'])\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (input_img, masks_true) in enumerate(test_loader):\n",
    "            input_img  = Variable(input_img).to(device, dtype=torch.float32)\n",
    "            masks_true = Variable(masks_true).to(device, dtype=torch.long)\n",
    "\n",
    "            masks_pred = model(input_img)\n",
    "            metrics = MetricsMethod(masks_pred.cpu(), masks_true, 8)\n",
    "            method['pa'].append(metrics.PA)\n",
    "            method['cpa'].append(metrics.CPA)\n",
    "            method['mpa'].append(metrics.MPA)\n",
    "            method['iou'].append(metrics.IoU)\n",
    "            method['miou'].append(metrics.MIoU)\n",
    "            method['map'].append(metrics.mAP)\n",
    "    \n",
    "    print('mAP@[.5:.95:.05]:', method['map'].sum()/len(test_loader*config['batch_size']), \n",
    "          ' PA:', method['pa'].sum()/len(test_loader*config['batch_size']), \n",
    "          ' MPA:', method['mpa'].sum()/len(test_loader*config['batch_size']), \n",
    "          ' mIoU:', method['miou'].sum()/len(test_loader*config['batch_size']))        \n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    losses = Average()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (input_img, masks_true) in enumerate(val_loader):\n",
    "            input_img  = Variable(input_img).to(device, dtype=torch.float32)\n",
    "            masks_true = Variable(masks_true).to(device, dtype=torch.long)\n",
    "\n",
    "            masks_pred = model(input_img)\n",
    "            \n",
    "            masks_true = F.one_hot(masks_true.squeeze(1), 8).permute(0, 3, 1, 2).float().to(f'cuda:{unet.device_ids[0]}')\n",
    "            loss = criterion(masks_pred, masks_true)\n",
    "\n",
    "            losses.update(loss.item(), masks_true.size(0))\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, train_loader, model, criterion, optimizer, scheduler, validation):\n",
    "    wandb.watch(model, criterion=criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    latest_model_path = find_latest_model(model_dir)\n",
    "    best_model_path = os.path.join(*[model_dir, 'model_best.pt'])\n",
    "\n",
    "    if latest_model_path is not None:\n",
    "        state = torch.load(latest_model_path)\n",
    "        epoch = state['epoch']\n",
    "        model.load_state_dict(state['model'])\n",
    "        epoch = epoch\n",
    "\n",
    "        assert Path(best_model_path).exists() == True, f'best model path {best_model_path} does not exist'\n",
    "        best_state = torch.load(latest_model_path)\n",
    "        min_val_los = best_state['valid_loss']\n",
    "\n",
    "        print(f'Restored model at epoch {epoch}. Min validation loss : {min_val_los}')\n",
    "        epoch += 1\n",
    "        print(f'Started training model from epoch {epoch}')\n",
    "    else:\n",
    "        print('Started training model from epoch 0')\n",
    "        epoch = 0\n",
    "        min_val_los = 9999\n",
    "\n",
    "    valid_losses = []\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epoch, config['n_epoch'] + 1):\n",
    "\n",
    "        tq = tqdm(total=(len(train_loader) * config['batch_size']))\n",
    "        tq.set_description(f'Epoch {epoch}')\n",
    "\n",
    "        running_losses = Average()\n",
    "\n",
    "        model.train()\n",
    "        for i, (input_img, masks_true) in enumerate(train_loader):\n",
    "            input_img  = Variable(input_img, requires_grad=True).to(device, dtype=torch.float32)\n",
    "            masks_true = Variable(masks_true, requires_grad=True).to(device, dtype=torch.long)\n",
    "\n",
    "            masks_pred = model(input_img)\n",
    "            output = masks_pred\n",
    "            \n",
    "            masks_true = F.one_hot(masks_true.squeeze(1), 8).permute(0, 3, 1, 2).float().to(f'cuda:{unet.device_ids[0]}')\n",
    "            loss = criterion(masks_pred, masks_true)\n",
    "            running_loss = loss\n",
    "            running_losses.update(running_loss.cpu().item(), masks_true.size(0))\n",
    "\n",
    "            tq.set_postfix(loss='{:.5f}'.format(running_losses.avg))\n",
    "            tq.update(config['batch_size'])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        valid_loss = validation(model, valid_loader, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f'valid_loss = {valid_loss:.5f}')\n",
    "        tq.close()\n",
    "        \n",
    "        wandb.log({\"training_loss\": running_losses.avg})\n",
    "        wandb.log({\"valid_loss\": valid_loss})\n",
    "        \n",
    "        epoch_model_path = os.path.join(*[model_dir, f'model_epoch_{epoch}.pt'])\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'valid_loss': valid_loss,\n",
    "            'train_loss': running_losses.avg\n",
    "        }, epoch_model_path)\n",
    "\n",
    "        if valid_loss < min_val_los:\n",
    "            min_val_los = valid_loss\n",
    "            torch.save({\n",
    "                'model': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'valid_loss': valid_loss,\n",
    "                'train_loss': running_losses.avg\n",
    "            }, best_model_path)\n",
    "    \n",
    "    finished_training_time = (time.time()-start_time)\n",
    "    print(f\"training_time(s): \", finished_training_time)\n",
    "    wandb.log({\"training_time(s)\": finished_training_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    n_epoch         = 20,\n",
    "    batch_size      = 16,\n",
    "    lr              = 0.001,\n",
    "    num_workers     = 12,\n",
    "    momentum        = 0.9,\n",
    "    weight_decay    = 1e-4,\n",
    "    dataset         = \"CCAgT\",\n",
    "    model           = \"ResUNet\",\n",
    "    optimizer       = \"Adam\",\n",
    "    scheduler       = \"StepLR\"\n",
    ")\n",
    "\n",
    "wandb_init = dict(\n",
    "#     job_type: Optional[str] = None,\n",
    "#     dir = None,\n",
    "    config = config,\n",
    "    project = \"ResUNet with CCAgT dataset\",\n",
    "#     entity = None,\n",
    "#     reinit = None,\n",
    "    tags = ['5v1'],\n",
    "#     group = None,\n",
    "    name = None,\n",
    "    notes = None,\n",
    "#     magic = None,\n",
    "#     config_exclude_keys = None,\n",
    "#     config_include_keys = None,\n",
    "#     anonymous = None,\n",
    "    mode = \"disabled\",  # \"online\",\"offline\",\"disabled\"\n",
    "#     allow_val_change = None,\n",
    "#     resume = None,\n",
    "#     force = None,\n",
    "#     tensorboard = None,\n",
    "#     sync_tensorboard = None,\n",
    "#     monitor_gym = None,\n",
    "    save_code = True,\n",
    "#     settings=None\n",
    ")\n",
    "\n",
    "model_dir = \"./model\"\n",
    "orig_img_dir = \"./dataset/images\"\n",
    "orig_msk_dir = \"./dataset/masks\"\n",
    "save_json = \"./dataset/dataset.json\"\n",
    "save_samples = \"./dataset/samples\"\n",
    "\n",
    "if save_samples != '':\n",
    "    os.makedirs(save_samples, exist_ok=True)\n",
    "    for sample in Path(save_samples).glob('*.jpg'):\n",
    "        os.remove(str(sample))\n",
    "\n",
    "if not os.path.exists(save_json):\n",
    "    obtain_path(img_dir=orig_img_dir, mask_dir=orig_msk_dir, target_path=str(save_json))\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.cuda.set_device(gpu_id)\n",
    "# device = torch.device(\"cuda:{}\".format(str(gpu_id)) if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", torch.cuda.current_device(), torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = [0.485, 0.456, 0.406]\n",
    "channel_stds  = [0.229, 0.224, 0.225]\n",
    "\n",
    "dataset = divide_dataset(save_json, [0.7,0.1,0.2])\n",
    "\n",
    "train_tsfm = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize(channel_means, channel_stds),\n",
    "                                transforms.RandomCrop((832, 832)), \n",
    "                                transforms.RandomRotation(90), \n",
    "                                transforms.RandomHorizontalFlip()])\n",
    "val_tsfm = transforms.Compose([ transforms.ToTensor(), \n",
    "                                transforms.Normalize(channel_means, channel_stds),\n",
    "                                transforms.RandomCrop((832, 832))])\n",
    "test_tsfm = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize(channel_means, channel_stds),\n",
    "                                transforms.RandomCrop((832, 832))])\n",
    "train_mask_tsfm = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.RandomCrop((832, 832)),\n",
    "                                      transforms.RandomRotation(90),\n",
    "                                      transforms.RandomHorizontalFlip()])\n",
    "mask_tsfm = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.RandomCrop((832, 832))])\n",
    "\n",
    "train_set = MyDataset(dataset, train_tsfm, train_mask_tsfm, 'train')\n",
    "valid_set = MyDataset(dataset, val_tsfm, mask_tsfm, 'valid')\n",
    "test_set = MyDataset(dataset, test_tsfm, mask_tsfm, 'test')\n",
    "\n",
    "train_loader = DataLoader(  train_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=config['num_workers'])\n",
    "valid_loader = DataLoader(  valid_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=config['num_workers'])\n",
    "test_loader = DataLoader(   test_set,\n",
    "                            config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=config['num_workers'])\n",
    "\n",
    "GraphVisualization(test_set, model=None, col=5, target_dir=save_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "os.environ[\"WANDB_API_KEY\"] = \"x\"*40\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'main.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1, 0, 2, 3\"\n",
    "\n",
    "model = ResUNet(Block=ResBlock, DecBlock=DecBlock)\n",
    "unet = torch.nn.DataParallel(model, device_ids=[1,0,2,3])\n",
    "unet.to(f'cuda:{unet.device_ids[0]}')\n",
    "\n",
    "optimizer = torch.optim.Adam(unet.parameters(), config['lr'],\n",
    "                             weight_decay=config['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30, 0.1)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "run = wandb.init(**wandb_init)\n",
    "\n",
    "train(config, train_loader, unet, criterion, optimizer, scheduler, validate)\n",
    "\n",
    "run.finish()\n",
    "\n",
    "# evaluate(unet.to(f'cuda:{unet.device_ids[0]}'), test_loader, criterion, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(model_dir=model_dir, target_dir=save_samples, title='Training/Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = os.path.join(*[model_dir, 'model_best.pt'])\n",
    "state = torch.load(best_model_path)\n",
    "unet.to(f'cuda:{unet.device_ids[0]}')\n",
    "unet.load_state_dict(state['model'])\n",
    "\n",
    "GraphVisualization(test_set, model=unet, col=5, target_dir=save_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b78e932638e08554df05c20af87637e4b1aca929fdb8a300e51156ee9428db4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
